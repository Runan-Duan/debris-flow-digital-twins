{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a7f3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import psycopg2\n",
    "from configparser import ConfigParser\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from config.settings import settings\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import psycopg2\n",
    "from configparser import ConfigParser\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f18a59",
   "metadata": {},
   "source": [
    "### Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e658914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(config):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    try:\n",
    "        # connecting to the PostgreSQL server\n",
    "        with psycopg2.connect(**config) as conn:\n",
    "            print('Connected to the PostgreSQL server.')\n",
    "            return conn\n",
    "    except (psycopg2.DatabaseError, Exception) as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4279949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(filename='../database/database.ini', section='postgresql'):\n",
    "    parser = ConfigParser()\n",
    "    parser.read(filename)\n",
    "\n",
    "    # get section, default to postgresql\n",
    "    config = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            config[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5154f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the PostgreSQL server.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<connection object at 0x000002A838CAEBD0; dsn: 'user=postgres password=xxx dbname=debris_flow_dt host=localhost', closed: 0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = load_config()\n",
    "connect(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5949e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_table(config):\n",
    "    \"\"\"\n",
    "    Create weather_data_hourly table if it doesn't exist\n",
    "    \"\"\"\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS weather_data_hourly (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        station_id VARCHAR(50) NOT NULL,\n",
    "        timestamp TIMESTAMP NOT NULL,\n",
    "        temperature_c FLOAT,\n",
    "        humidity_percent FLOAT,\n",
    "        pressure_hpa FLOAT,\n",
    "        wind_speed_kmh FLOAT,\n",
    "        gust_speed_kmh FLOAT,\n",
    "        precipitation_mm FLOAT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        data_source VARCHAR(50) DEFAULT 'AWEKAS_TABLE',\n",
    "        UNIQUE(station_id, timestamp)\n",
    "    );\n",
    "    \n",
    "    CREATE INDEX IF NOT EXISTS idx_station_timestamp \n",
    "    ON weather_data_hourly(station_id, timestamp);\n",
    "    \n",
    "    CREATE INDEX IF NOT EXISTS idx_timestamp \n",
    "    ON weather_data_hourly(timestamp);\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with psycopg2.connect(**config) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(create_table_query)\n",
    "                conn.commit()\n",
    "                # logger.info(\"Table 'weather_data_hourly' created/verified\")\n",
    "                print(\"Table 'weather_data_hourly' created/verified\")\n",
    "                return True\n",
    "    except (psycopg2.DatabaseError, Exception) as error:\n",
    "        # logger.error(f\"Error creating table: {error}\")\n",
    "        print(f\"Error creating table: {error}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c6642",
   "metadata": {},
   "source": [
    "### Wrap data from web\n",
    "AWEKAS WEATHER DATA: Grossglockner Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2000cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = \"34362\"\n",
    "base_url = \"https://stationsweb.awekas.at\"\n",
    "urls = {\n",
    "            'index-tab': f\"{base_url}/en/{station_id}/index-tab\",\n",
    "            'table': f\"{base_url}/en/{station_id}/table\",\n",
    "            'data': f\"{base_url}/en/{station_id}/data\",\n",
    "            'statistic': f\"{base_url}/en/{station_id}/statistic\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce6a9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run without GUI\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--window-size=1920,1080')\n",
    "chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e1177da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_cookies_ionic(driver, timeout=10):\n",
    "    try:\n",
    "        # Wait until ion-modal is present\n",
    "        WebDriverWait(driver, timeout).until(\n",
    "            lambda d: d.execute_script(\n",
    "                \"return document.querySelector('ion-modal#cookie-banner') !== null\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Click \"Accept all\" inside Shadow DOM\n",
    "        driver.execute_script(\"\"\"\n",
    "            const modal = document.querySelector('ion-modal#cookie-banner');\n",
    "            if (!modal) return;\n",
    "\n",
    "            const root = modal.shadowRoot;\n",
    "            if (!root) return;\n",
    "\n",
    "            const buttons = modal.querySelectorAll('ion-button');\n",
    "            for (const btn of buttons) {\n",
    "                if (btn.innerText.trim().toLowerCase().includes('accept')) {\n",
    "                    btn.click();\n",
    "                    return;\n",
    "                }\n",
    "            }\n",
    "        \"\"\")\n",
    "        print(\"Cookie banner accepted\")\n",
    "\n",
    "        # Small wait to allow modal to close\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"No cookie banner found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eca38fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookie banner accepted\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 15)\n",
    "driver.get(urls['table'])\n",
    "accept_cookies_ionic(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "723bc19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 19, 2026\n"
     ]
    }
   ],
   "source": [
    "date_element = wait.until(\n",
    "    EC.visibility_of_element_located(\n",
    "        (By.XPATH, \"//div[contains(@class,'date') and contains(@class,'visible')]//ion-text\")\n",
    "    )\n",
    ")\n",
    "\n",
    "date_text = date_element.text\n",
    "print(date_text)   # January 19, 2026\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960deab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date found: 2026-01-19\n"
     ]
    }
   ],
   "source": [
    "date_obj = datetime.strptime(date_text, \"%B %d, %Y\")\n",
    "print(f\"Date found: {date_obj.date()}\")   # 2026-01-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36291cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wait.until(\n",
    "    EC.visibility_of_element_located(\n",
    "        (By.XPATH, \"//div[contains(@class,'card') and contains(@class,'visible')]//table\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9ec6e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': '00:00', 'temperature': '25.9 °F', 'humidity': '94.0%', 'pressure': '0.00 inHg', 'wind': '0.4 mph', 'gust': '0.4 mph', 'precipitation': '0.00 in'}\n",
      "{'time': '01:00', 'temperature': '25.5 °F', 'humidity': '94.0%', 'pressure': '0.00 inHg', 'wind': '0.0 mph', 'gust': '0.0 mph', 'precipitation': '0.00 in'}\n",
      "{'time': '02:00', 'temperature': '25.5 °F', 'humidity': '94.0%', 'pressure': '0.00 inHg', 'wind': '0.2 mph', 'gust': '0.2 mph', 'precipitation': '0.00 in'}\n",
      "{'time': '03:00', 'temperature': '25.2 °F', 'humidity': '94.0%', 'pressure': '0.00 inHg', 'wind': '0.0 mph', 'gust': '0.0 mph', 'precipitation': '0.00 in'}\n",
      "{'time': '04:00', 'temperature': '25.2 °F', 'humidity': '94.0%', 'pressure': '0.00 inHg', 'wind': '0.2 mph', 'gust': '0.2 mph', 'precipitation': '0.00 in'}\n",
      "{'time': '05:00', 'temperature': '25.0 °F', 'humidity': '94.0%', 'pressure': '0.00 inHg', 'wind': '0.0 mph', 'gust': '0.0 mph', 'precipitation': '0.00 in'}\n",
      "{'time': '06:00', 'temperature': '25.0 °F', 'humidity': '94.0%', 'pressure': '0.00 inHg', 'wind': '0.1 mph', 'gust': '0.1 mph', 'precipitation': '0.00 in'}\n",
      "{'time': '07:00', 'temperature': '24.6 °F', 'humidity': '93.0%', 'pressure': '0.00 inHg', 'wind': '0.6 mph', 'gust': '0.6 mph', 'precipitation': '0.00 in'}\n",
      "{'time': '08:00', 'temperature': '24.3 °F', 'humidity': '93.0%', 'pressure': '0.00 inHg', 'wind': '0.4 mph', 'gust': '0.4 mph', 'precipitation': '0.00 in'}\n"
     ]
    }
   ],
   "source": [
    "rows = table.find_elements(By.XPATH, \".//tbody/tr\")\n",
    "\n",
    "data = []\n",
    "\n",
    "for row in rows:\n",
    "    cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "    row_data = {\n",
    "        \"time\": cells[0].text,\n",
    "        \"temperature\": cells[1].text,\n",
    "        \"humidity\": cells[2].text,\n",
    "        \"pressure\": cells[3].text,\n",
    "        \"wind\": cells[4].text,\n",
    "        \"gust\": cells[5].text,\n",
    "        \"precipitation\": cells[6].text\n",
    "    }\n",
    "\n",
    "    data.append(row_data)\n",
    "\n",
    "for row in data:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffeee707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_one_day(driver, wait):\n",
    "    # Read date\n",
    "    date_element = wait.until(\n",
    "        EC.visibility_of_element_located(\n",
    "            (By.XPATH, \"//div[contains(@class,'date') and contains(@class,'visible')]//ion-text\")\n",
    "        )\n",
    "    )\n",
    "    date_text = date_element.text\n",
    "    date_obj = datetime.strptime(date_text, \"%B %d, %Y\").date()\n",
    "\n",
    "    # Read table\n",
    "    table = wait.until(\n",
    "        EC.visibility_of_element_located(\n",
    "            (By.XPATH, \"//div[contains(@class,'card') and contains(@class,'visible')]//table\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    rows = table.find_elements(By.XPATH, \".//tbody/tr\")\n",
    "    day_data = []\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "        def clean_num(text):\n",
    "            clean = re.sub(r\"[^\\d\\.\\-]\", \"\", text)\n",
    "            return float(clean) if clean else 0.0\n",
    "\n",
    "        time_str = cells[0].text\n",
    "        timestamp = datetime.combine(\n",
    "            date_obj,\n",
    "            datetime.strptime(time_str, \"%H:%M\").time()\n",
    "        )\n",
    "\n",
    "        day_data.append({\n",
    "            \"timestamp\": timestamp,\n",
    "            \"precipitation_mm\": clean_num(cells[6].text),\n",
    "            \"temperature_c\": clean_num(cells[1].text),\n",
    "            \"humidity_percent\": clean_num(cells[2].text),\n",
    "            \"wind_kmh\": clean_num(cells[4].text)\n",
    "        })\n",
    "\n",
    "    return date_obj, day_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c3048b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_previous_day(driver, wait, current_date_text):\n",
    "    prev_button = wait.until(\n",
    "        EC.element_to_be_clickable(\n",
    "            (By.XPATH, \"//div[contains(@class,'date') and contains(@class,'visible')]//ion-buttons[contains(@class,'left')]//ion-button\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    prev_button.click()\n",
    "\n",
    "    # Wait until date text changes\n",
    "    wait.until(\n",
    "        lambda d: d.find_element(\n",
    "            By.XPATH,\n",
    "            \"//div[contains(@class,'date') and contains(@class,'visible')]//ion-text\"\n",
    "        ).text != current_date_text\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "487fbef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 18 rows for 2026-01-19\n",
      "Collected 18 rows for 2026-01-18\n",
      "Collected 24 rows for 2026-01-17\n",
      "Collected 24 rows for 2026-01-16\n",
      "Collected 24 rows for 2026-01-15\n",
      "Collected 24 rows for 2026-01-14\n",
      "Collected 24 rows for 2026-01-13\n",
      "Collected 24 rows for 2026-01-12\n",
      "Collected 24 rows for 2026-01-11\n",
      "Collected 24 rows for 2026-01-10\n",
      "Collected 24 rows for 2026-01-09\n",
      "Collected 24 rows for 2026-01-08\n",
      "Collected 24 rows for 2026-01-07\n",
      "Collected 24 rows for 2026-01-06\n"
     ]
    }
   ],
   "source": [
    "# driver.get(urls['table'])\n",
    "\n",
    "all_data = []\n",
    "dates_collected = []\n",
    "days = 14\n",
    "for i in range(days):\n",
    "    date_element = wait.until(\n",
    "        EC.visibility_of_element_located(\n",
    "            (By.XPATH, \"//div[contains(@class,'date') and contains(@class,'visible')]//ion-text\")\n",
    "        )\n",
    "    )\n",
    "    current_date_text = date_element.text\n",
    "\n",
    "    date_obj, day_data = scrape_one_day(driver, wait)\n",
    "    dates_collected.append(date_obj)\n",
    "    all_data.extend(day_data)\n",
    "\n",
    "    print(f\"Collected {len(day_data)} rows for {date_obj}\")\n",
    "\n",
    "    if i < (days-1):\n",
    "        go_to_previous_day(driver, wait, current_date_text)\n",
    "\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78097a8",
   "metadata": {},
   "source": [
    "### Computing antecedent rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b166f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antecedent_rainfall(data, decay=0.84):\n",
    "    data_sorted = sorted(data, key=lambda x: x[\"timestamp\"], reverse=True)\n",
    "\n",
    "    rain_eff = 0.0\n",
    "    last_day = data_sorted[0][\"timestamp\"].date()\n",
    "\n",
    "    for row in data_sorted:\n",
    "        days_ago = (last_day - row[\"timestamp\"].date()).days\n",
    "        rain_eff += row[\"precipitation_mm\"] * (decay ** days_ago)\n",
    "\n",
    "    return rain_eff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e06dbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective antecedent rainfall: 0.065 mm\n"
     ]
    }
   ],
   "source": [
    "ra_eff = antecedent_rainfall(all_data)\n",
    "print(f\"Effective antecedent rainfall: {ra_eff:.3f} mm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
